{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert files to utf-8 to be used later for comparing with news websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encodings.aliases import aliases\n",
    "\n",
    "alias_list=set([v for k, v in aliases.items()])\n",
    "# alias_list = ['cp1252','utf-9']\n",
    "alias_list = ['ascii',\n",
    "              'base64_codec', 'cp037',\n",
    "              'cp1026',\n",
    "              'cp1125',\n",
    "              'cp1140',\n",
    "              'cp1250',\n",
    "              'cp1251',\n",
    "              'cp1252',\n",
    "              'cp1253',\n",
    "              'cp1254',\n",
    "              'cp1255',\n",
    "              'cp1256',\n",
    "              'cp1257',\n",
    "              'cp1258', 'hex_codec', 'iso8859_10',\n",
    "              'iso8859_11',\n",
    "              'iso8859_13',\n",
    "              'iso8859_14',\n",
    "              'iso8859_15',\n",
    "              'iso8859_16',\n",
    "              'iso8859_2',\n",
    "              'iso8859_3',\n",
    "              'iso8859_4',\n",
    "              'iso8859_5',\n",
    "              'iso8859_6',\n",
    "              'iso8859_7',\n",
    "              'iso8859_8',\n",
    "              'iso8859_9', 'utf_16',\n",
    "              'utf_16_be',\n",
    "              'utf_16_le',\n",
    "              'utf_32',\n",
    "              'utf_32_be',\n",
    "              'utf_32_le',\n",
    "              'utf_7',\n",
    "              'utf_8', \n",
    "              'unicode_escaped']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '../res/raw/.ipynb_checkpoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     19\u001b[0m    \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../res/raw/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfile_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     21\u001b[0m    text \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '../res/raw/.ipynb_checkpoints'"
     ]
    }
   ],
   "source": [
    "#NOTE: ONLY RUN THIS WHEN YOU ARE SATISFIED WITH RAW FILES' CONTENTS\n",
    "import os\n",
    "import time\n",
    "import concurrent.futures\n",
    "\n",
    "def encode_file_given_alias(alias,text):\n",
    "   try:\n",
    "      text = text.decode(alias).encode('utf-8')\n",
    "   except Exception as e:\n",
    "      pass\n",
    "   return text\n",
    "\n",
    "raw_file_names = os.listdir('../res/raw/')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for file_name in raw_file_names:\n",
    "   if file_name.endswith('.csv'):\n",
    "      continue\n",
    "   with open(f'../res/raw/{file_name}', 'rb') as f:\n",
    "      text = f.read()\n",
    "   with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "      args = ((alias, text) for alias in alias_list)\n",
    "      for result in executor.map(lambda p:  encode_file_given_alias(*p), args):\n",
    "         text = result\n",
    "   with open(f'../res/raw/{file_name}', 'wb') as f:\n",
    "      f.write(text)\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE WRITER\n",
    "from pathlib import Path\n",
    "# NOTE: To use the method, the argument must have the same name as the\n",
    "# method that it is calling. Check all the methods to know what arguments to pass\n",
    "# Replace will overwrite existing file with newly scraped data\n",
    "\n",
    "\n",
    "def create_entity_file(output_file_name, replace=False, encoding='utf-8'):\n",
    "   path = Path(f'../res/raw/{output_file_name}.txt')\n",
    "   if not path.is_file() and not replace:\n",
    "      entities_list = globals()[f'get_{output_file_name}_list']()\n",
    "      file = open(f'../res/raw/{output_file_name}.txt', \"x\",encoding=encoding)\n",
    "      for x in entities_list:\n",
    "         file.write(f'{x}\\n')\n",
    "\n",
    "   elif path.is_file and replace:\n",
    "      entities_list = globals()[f'get_{output_file_name}_list']()\n",
    "      file = open(f'../res/raw/{output_file_name}.txt', \"w\", encoding=encoding)\n",
    "      for x in entities_list:\n",
    "         file.write(f'{x}\\n')\n",
    "\n",
    "   print(f'DONE CREATING {output_file_name} FILE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_provinces_list():\n",
    "   with open('../res/raw/tourist_dests.txt', encoding='utf-8') as province_file:\n",
    "      return [province\n",
    "            .lower()\n",
    "            .replace('\\n','') \n",
    "            .strip()\n",
    "            for province in province_file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_tourist_dest_list():\n",
    "   with open('../res/raw/tourist_dests.txt') as tourist_dest_file:\n",
    "      return [tourist_dest\n",
    "              .replace('\\n', '')\n",
    "              for tourist_dest in tourist_dest_file.readlines()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_cities_list():\n",
    "   raw_cities_df = pd.read_csv(\n",
    "       '../res/raw/worldcities.csv', index_col=False, encoding='utf-8')\n",
    "   ph_cities_df = raw_cities_df.loc[raw_cities_df['iso3'] == 'PHL']\n",
    "   ph_cities_df = ph_cities_df[['city']]\n",
    "   ph_cities_df = ph_cities_df['city']\n",
    "   return ph_cities_df.to_list()\n",
    "\n",
    "create_entity_file('cities',replace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('READING PROVINCE LIST')\n",
    "provinces_list = get_provinces_list()\n",
    "print('READING CITIES LIST')\n",
    "cities_list = get_cities_list()\n",
    "print('READING TOURIST DESTINATION LIST')\n",
    "tourist_dest_list = get_tourist_dest_list()\n",
    "\n",
    "print('COMPLETED READING FILES')\n",
    "\n",
    "all_locations = provinces_list+cities_list+tourist_dest_list \n",
    "all_locations = [loc.lower() for loc in all_locations]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a location exists\n",
    "'vigan' in ''.join(all_locations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "final_dataset_df = pd.DataFrame(columns=['entity','tag'])\n",
    "\n",
    "for file_name in os.listdir('../res/raw/'):\n",
    "   entity_data_df = pd.DataFrame(columns=['entity', 'tag'])\n",
    "   if file_name.endswith(\".txt\") and not file_name.startswith(\"final\"):\n",
    "      with open(f'../res/raw/{file_name}', errors='ignore') as file:\n",
    "         file_name = file_name.split('.txt')[0]\n",
    "         if file_name=='cities' or file_name=='provinces':\n",
    "            tag = 'GPE'\n",
    "         elif file_name=='events' or file_name =='holidays':\n",
    "            tag = 'EVT'\n",
    "         elif 'name' in file_name:\n",
    "            tag = 'PER'\n",
    "         elif file_name == 'tourist_dests':\n",
    "            tag = 'LOC'\n",
    "         elif file_name =='organizations' or \\\n",
    "              file_name =='local_companies' or \\\n",
    "              file_name =='gov_agencies' or \\\n",
    "              file_name =='gov_acronym':\n",
    "               tag ='ORG'\n",
    "         entities_list = []\n",
    "         \n",
    "         for line in file.readlines():\n",
    "            line = ''.join(line.strip().lower().split('\\n'))\n",
    "            if ',' in line or '\"' in line or len(line) < 3:\n",
    "               print(line)\n",
    "               continue\n",
    "            else:\n",
    "               entities_list.append(line)\n",
    "\n",
    "         entity_data_df['entity'] = entities_list\n",
    "         entity_data_df['tag'] = len(entity_data_df)*[tag]\n",
    "         # display(entity_data_df)\n",
    "         final_dataset_df =  final_dataset_df.append(entity_data_df, ignore_index=True)\n",
    "\n",
    "\n",
    "final_dataset_df.to_csv('../res/preprocessed/final_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_ents = ['Benjamin','Magalong','Sinulog Festival', 'Quiapo', 'Mani']\n",
    "sample_text_orig = 'Mayor Benjamin Magalong spearheaded the celebration of Sinulog Festival in Quiapo, Manila'\n",
    "\n",
    "sample_text = ' '.join(sample_text_orig.split(','))\n",
    "for ent in matched_ents:\n",
    "  sample_text = sample_text_orig\n",
    "  sample_text =  sample_text.split(' ')\n",
    "  ent = ent.split(' ')\n",
    "  check = all(item in sample_text for item in ent)\n",
    "\n",
    "  if check:\n",
    "    if len(ent) ==1:\n",
    "      ent =ent[0]\n",
    "    else:\n",
    "      ent = ' '.join(ent)\n",
    "    print(ent)\n",
    "    start_idx = ' '.join(sample_text).find(ent)\n",
    "    if start_idx==-1:\n",
    "      ent_words = ent.split(' ')\n",
    "      # If more than two words yung entity\n",
    "      if len(ent_words) > 1 and ent in sample_text:\n",
    "        ent_first_word = ent_words[0]\n",
    "        ent_last_word = ent_words[len(ent_words)-1]\n",
    "        start_idx = sample_text.find(ent_first_word)\n",
    "        end_idx = sample_text.find(ent_last_word)\n",
    "        end_idx = end_idx + len(ent_last_word)-1\n",
    "      else:\n",
    "        continue\n",
    "    else:\n",
    "      end_idx = start_idx+len(ent)\n",
    "    print(f'start: {start_idx} | end: {end_idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentt = 'dog'\n",
    "len(sentt.split(' '))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cef9e06bb236b2a8629b07e87a04b187b952a0f661eff5533360a155783f0c33"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
