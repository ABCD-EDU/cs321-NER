{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HELPER METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE WRITER\n",
    "from pathlib import Path\n",
    "# NOTE: To use the method, the argument must have the same name as the \n",
    "# method that it is calling. Check all the methods to know what arguments to pass\n",
    "# Replace will overwrite existing file with newly scraped data\n",
    "\n",
    "def create_entity_file(output_file_name, replace=False):\n",
    "   path = Path(f'../res/raw/{output_file_name}.txt')\n",
    "   if not path.is_file() and not replace:\n",
    "      entities_list = globals()[f'scrape_{output_file_name}_list']()\n",
    "      file = open(f'../res/raw/{output_file_name}.txt', \"x\")\n",
    "      for x in entities_list:\n",
    "         file.write(f'{x}\\n')\n",
    "\n",
    "   elif path.is_file and replace:\n",
    "      entities_list = globals()[f'scrape_{output_file_name}_list']()\n",
    "      file = open(f'../res/raw/{output_file_name}.txt', \"w\")\n",
    "      for x in entities_list:\n",
    "         file.write(f'{x}\\n')\n",
    "\n",
    "   print(f'DONE CREATING {output_file_name} FILE')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Local Tourist Destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, NavigableString\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "\n",
    "def scrape_tourist_dests_list():\n",
    "   tourist_dest_url = 'https://www.traveling-up.com/travel-guide-81-provinces-of-the-philippines'\n",
    "\n",
    "   driver = webdriver.Firefox(executable_path='geckodriver.exe')\n",
    "   driver.get(tourist_dest_url)\n",
    "   html = driver.page_source\n",
    "\n",
    "   data = BeautifulSoup(html,'lxml')\n",
    "   ul_list= data.find(\"div\",{\"class\":\"entry-content\"}).find_all(\"ul\")\n",
    "\n",
    "   tourist_dest_list = []\n",
    "   for ul in ul_list:\n",
    "      li_children = ul.findChildren(\"li\", recursive=False)\n",
    "      for li in li_children:\n",
    "         if type(li) == NavigableString:\n",
    "            continue\n",
    "         elif 'Top tourist spots:' in li.text:\n",
    "            # Remove top tourist spots from the text and get the 2nd item which is \n",
    "            # texts with tourist destinations that are separated by comma\n",
    "            cleaned_tourist_dest = li.text.split('Top tourist spots:')[1]\n",
    "            # Split the text to get items as list\n",
    "            cleaned_tourist_dest = cleaned_tourist_dest.split(',')\n",
    "            # Get only the data that comes before a parentheses\n",
    "            # Get the lower case \n",
    "            # Remove 'xa0' character using space\n",
    "            cleaned_tourist_dest = [dest.split('(')[0]\n",
    "                                    .lower()\n",
    "                                    .strip()\n",
    "                                    .replace(u'\\xa0',' ')\n",
    "                                    for dest in cleaned_tourist_dest]\n",
    "            # Remove empty strings from the list\n",
    "            cleaned_tourist_dest = list(filter(None, cleaned_tourist_dest))\n",
    "            # Finally append values to the tourist_dest_list\n",
    "            tourist_dest_list = tourist_dest_list + cleaned_tourist_dest\n",
    "   print('DONE SCRAPING...')\n",
    "   return tourist_dest_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE CREATING tourist_dests FILE\n"
     ]
    }
   ],
   "source": [
    "create_entity_file('tourist_dests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Surnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_surnames_list():\n",
    "    url = 'https://baguiocityguide.com/how-common-is-your-last-name-here-are-the-top-1000-filipino-surnames'\n",
    "\n",
    "    header = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "    }\n",
    "\n",
    "    r = requests.get(url, headers=header)\n",
    "    dfs = pd.read_html(r.text)\n",
    "\n",
    "    surnames_list = []\n",
    "    for table in dfs:\n",
    "        surnames = [surname.lower() for surname in table['Surname'].to_list()]\n",
    "        surnames_list = surnames_list + surnames\n",
    "    return surnames_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE CREATING surnames FILE\n"
     ]
    }
   ],
   "source": [
    "create_entity_file('surnames')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get First names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_first_names_list():\n",
    "    url = 'https://forebears.io/philippines/forenames'\n",
    "\n",
    "    header = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "    }\n",
    "\n",
    "    r = requests.get(url, headers=header)\n",
    "    dfs = pd.read_html(r.text)\n",
    "\n",
    "    firstnames_list = []\n",
    "    for table in dfs:\n",
    "        first_names = [first_name.lower() for first_name in table['Forename'].to_list()]\n",
    "        firstnames_list = firstnames_list + first_names\n",
    "    return firstnames_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE CREATING first_names FILE\n"
     ]
    }
   ],
   "source": [
    "create_entity_file('first_names')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Local Events "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_events_list():\n",
    "   url = 'https://www.tpb.gov.ph/tpb-calendar-of-promotions-and-marketing-activities/calendar-of-philippine-festivals-and-monthly-observances-theme/'\n",
    "\n",
    "   header = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "    }\n",
    "\n",
    "   r = requests.get(url, headers=header)\n",
    "   dfs = pd.read_html(r.text)\n",
    "   \n",
    "   events_list = []\n",
    "   months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "   for table in dfs:\n",
    "      for event in table['Name of Event'].to_list():\n",
    "         if event.lower() not in map(str.lower, months):\n",
    "            events_list.append(event.lower())               \n",
    "\n",
    "   return events_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE CREATING events FILE\n"
     ]
    }
   ],
   "source": [
    "create_entity_file('events')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET local companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_local_companies_list():\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_companies_of_the_Philippines'\n",
    "\n",
    "    header = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "    }\n",
    "\n",
    "    r = requests.get(url, headers=header)\n",
    "    dfs = pd.read_html(r.text)\n",
    "\n",
    "    local_companies_list = []\n",
    "    for idx, table in enumerate(dfs):\n",
    "        # Skip first table\n",
    "        if idx==0:\n",
    "            continue\n",
    "        \n",
    "        company_names = [company_name.lower()\n",
    "                       for company_name in table['Name'].to_list()]\n",
    "        local_companies_list = local_companies_list + company_names\n",
    "    return local_companies_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE CREATING local_companies FILE\n"
     ]
    }
   ],
   "source": [
    "create_entity_file('local_companies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get NGOS and Government Organizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_organizations_list():\n",
    "   orgs_list = []\n",
    "\n",
    "   for i in range(3):\n",
    "      \n",
    "      url = f'https://worldjusticeproject.org/resource-hub/leading-organizations?factor=All&geography=174&name=&order=field_organization_name_trans&sort=asc&page={i}'\n",
    "\n",
    "      header = {\n",
    "         \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "         \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "      }\n",
    "\n",
    "      r = requests.get(url, headers=header)\n",
    "      dfs = pd.read_html(r.text)\n",
    "      \n",
    "      \n",
    "      for table in dfs:\n",
    "         for org in table['Organization Name'].to_list():\n",
    "            orgs_list.append(org)\n",
    "\n",
    "   return orgs_list\n",
    "try:\n",
    "   scrape_organizations_list()\n",
    "except Exception as e:\n",
    "   print(f'{e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE CREATING organizations FILE\n"
     ]
    }
   ],
   "source": [
    "create_entity_file('organizations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get government agencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cef9e06bb236b2a8629b07e87a04b187b952a0f661eff5533360a155783f0c33"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
